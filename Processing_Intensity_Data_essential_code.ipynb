{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9620781a-e133-41b6-a93f-11a8c1f351d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as nump \n",
    "import math \n",
    "import pandas as pan #reading lines from csv file intp an array later \n",
    "import os \n",
    "import glob # getting the csv files which are stored in the same folder\n",
    "import tkinter as tkin\n",
    "from tkinter import filedialog\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import ruptures as rpt\n",
    "from scipy.signal import savgol_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a56dcaa-7068-48c2-8c7c-8d6a0278daea",
   "metadata": {},
   "outputs": [],
   "source": [
    "root=tkin.Tk()\n",
    "root.withdraw() \n",
    "my_working_path= filedialog.askdirectory(title=\"Choose folder in which other folders with the csv files from the linescan are found:\")# opens a window on your computer to select the folder\n",
    "os.chdir(my_working_path) \n",
    "work=os.getcwd()\n",
    "my_csv_files = glob.glob(os.path.join(work, \"*.csv\")) # identifies the csv files in this directory\n",
    "print(my_csv_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c1a3d3-92c4-4721-9887-afea28170ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in range(len(my_csv_files)):\n",
    "    if \"Kopie\" not in my_csv_files[l]:\n",
    "        #later insert code for title search \n",
    "        if \"Values_Plot\" and \"alphatub\" in my_csv_files[l]:\n",
    "            print(my_csv_files[l])\n",
    "            Data_568=pan.read_csv(my_csv_files[l],sep=',',encoding = 'unicode_escape')# using panda for reading the csv file in Dataframe\n",
    "            plt.plot(Data_568.iloc[:,0],Data_568.iloc[:,1], c=\"b\")# Data_568.iloc[:,0] is x-Data and Data_568.iloc[:,1] is y-data from panda frame \n",
    "            array_568=Data_568.to_numpy() # array_568 contains the alphatubulin Data from the Lineprofile over a single MT \n",
    "            #print(Data_568)\n",
    "            #print(array_568)\n",
    "            #print(Data_568.iloc[:,1])\n",
    "        elif \"Values_Plot\" and \"acetyl\" in my_csv_files[l]:\n",
    "            print(my_csv_files[l])\n",
    "            Data_488=pan.read_csv(my_csv_files[l],sep=',', encoding = 'unicode_escape')\n",
    "            plt.plot(Data_488.iloc[:,0],Data_488.iloc[:,1], c=\"m\")  \n",
    "            plt.xlabel(\"Distance [px]\")\n",
    "            plt.ylabel(\"Intensity [Au]\")\n",
    "            #plt.title(\"Intensity of Lineprofile of {} stabilized  Microtubule after {} min alphaTAT1 incubation\".format(tax, time))\n",
    "            array_488=Data_488.to_numpy()# array_488 contains the acetylated tubulin Data from the Lineprofile over a single MT \n",
    "    #print(my_csv_files[l],reading) #all the csv files in the directory with the same indetifier\n",
    "print(Data_488)\n",
    "print(Data_568)\n",
    "#print(Data_568.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e404eb0d-8a1f-4207-9620-7fe4aa8f069e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting pixel in µm 0.045400065, 22.0264 pixel/µm\n",
    "Data_568[\"Distance_µm\"] = Data_568.iloc[:,0].multiply(0.0454)\n",
    "Data_488[\"Distance_µm\"] = Data_488.iloc[:,0].multiply(0.0454)\n",
    "position= Data_568.columns.get_loc(\"Distance_µm\")\n",
    "position_488= Data_488.columns.get_loc(\"Distance_µm\")#\n",
    "array_488_um=Data_488.to_numpy()\n",
    "array_568_um=Data_568.to_numpy()\n",
    "#print(position)\n",
    "print(position_488)\n",
    "#Data_568.iloc[:,3] = Data_568.iloc[:,0].multiply(0.0454)\n",
    "print(Data_568.iloc[:,position])\n",
    "print(array_488_um)\n",
    "print(Data_568)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d908903-1dae-4e9e-8451-9807137487bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#detection of changepoint \n",
    "#alphatubulin Start and End Microtubule \n",
    "algo_new=rpt.Dynp(model=\"rbf\").fit_predict(array_568,n_bkps=4) #works definetly better forn O Minutestax\n",
    "#algo3=rpt.Dynp(model=\"rbf\").fit_predict(array_568,n_bkps=2)\n",
    "\n",
    "#Trying to detect patches in acetylation Intensity signal \n",
    "algo2=rpt.Pelt(model=\"rbf\").fit_predict(array_488,1.1) # Increase penalty from 1.1 to achieve better fit for acetylated Data \n",
    "#  fit_predict(self, signal, pen) # Fit to the signal and return the optimal breakpoints. Helper method to call fit and predict once\n",
    "\n",
    "# display\n",
    "rpt.display(array_568[:,1],algo_new,algo_new, computed_chg_pts_linewidth=0.5)\n",
    "\n",
    "rpt.display(array_488[:,1],algo2, algo2,computed_chg_pts_linewidth=0.5)\n",
    "#just selects the intensity values for the display function of rupture\n",
    "\n",
    "#costfunction with penalty 800 aber ohne determination of number of changepoints for acetylated signal patches \n",
    "#minimum distance between changepoints \n",
    "# ein parameter ändern und dann vergleichen \n",
    "plt.show()\n",
    "print(algo_new)\n",
    "print(array_568[70:71,1])\n",
    "print(array_488[70:71,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c460a630-ef51-4638-89da-dd8fff9d838d",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_border=algo_new[0]\n",
    "up_border=algo_new[len(algo_new)-2]\n",
    "leng_pix=up_border-algo_new[0]\n",
    "print(\"lower_border_x:\", l_border, \"upper_border_x:\", up_border, \"length in pixel:\",leng_pix) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cd2a3f-a99f-4442-804e-9a1c2d4a88de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the array based on the defined borders(=Microtubule start and end) \n",
    "n_ar_488_um= array_488_um[l_border:up_border+1,]#slicing the array based on the borders \n",
    "end= len(n_ar_488_um[:,0])\n",
    "leng_um=n_ar_488_um[end-1:end,2]-n_ar_488_um[0:1,2]\n",
    "#print(n_ar_488_um[end-1:end,0])\n",
    "l_border_um_48=n_ar_488_um[0:1,2]\n",
    "up_border_um_48=n_ar_488_um[end-1:end,2]\n",
    "print(\"lower_border_x:\", l_border_um_48, \"upper_border_x:\", up_border_um_48, \"length in µm:\",leng_um )\n",
    "\n",
    "n_ar_568_um= array_568_um[l_border:up_border+1,]#slicing the array based on the borders \n",
    "leng_um_568=n_ar_568_um[end-1:end,2]-n_ar_568_um[0:1,2]\n",
    "l_border_um_568=n_ar_568_um[0:1,2]\n",
    "up_border_um_568=n_ar_568_um[end-1:end,2]\n",
    "print(\"lower_border_x:\", l_border_um_568, \"upper_border_x:\", up_border_um_568, \"length in µm:\",leng_um_568 )\n",
    "\n",
    "#print(n_ar_488_um[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb24b44-7852-43a8-80d7-f99a69286ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "#integral = nump.trapz(array_488[:,1], array_488[:,0])\n",
    "#print(integral) \n",
    "\n",
    "integral_alpha = nump.trapz(n_ar_568_um[:,1], n_ar_568_um[:,0])\n",
    "print(integral_alpha) \n",
    "\n",
    "integral_borders= nump.trapz(n_ar_488_um[:,1], n_ar_488_um[:,0])\n",
    "print(integral_borders) \n",
    "\n",
    "#Summe_border=nump.sum(n_ar_488_um[:,1])\n",
    "#print(\"Summe b:\", Summe_border)\n",
    "#print(n_ar_488_um[:,1])\n",
    "\n",
    "Summe=nump.sum(array_488[:,1])\n",
    "print(\"Summe 488:\", Summe)\n",
    "\n",
    "Summe_alpha=nump.sum(array_568[:,1])\n",
    "print(\"Summe 568:\", Summe_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5502c13-719c-4853-8338-a2c8b450b353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating values for diagramm \n",
    "array_time= [0,5,10,20,60]\n",
    "value_length_48= leng_um\n",
    "value_time_48=10 #time \n",
    "value_int_48=integral_borders\n",
    "\n",
    "y48_value= integral_borders/leng_um\n",
    "print(y48_value)\n",
    "x48_value= 10 #time \n",
    "print(\"y488:\",y48_value[0], \"x488:\", x48_value)\n",
    "string48_y= str(y48_value[0])\n",
    "string48_x=str(x48_value)+\",\"\n",
    "print(string48_y, string48_x)\n",
    "\n",
    "y568_value= integral_alpha/leng_um_568\n",
    "x568_value= 10 #time \n",
    "print(\"y568:\",y568_value[0], \"x568:\", x568_value)\n",
    "string568_y= str(y568_value[0])\n",
    "string568_x=str(x568_value)+\",\"\n",
    "print(string568_y, string568_x)\n",
    "\n",
    "#sum acetyl/sum alpha \n",
    "\n",
    "y_sumAC_sumAL= y48_value/y568_value\n",
    "string_sumdiv_y= str(y_sumAC_sumAL[0])\n",
    "print(string_sumdiv_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d21d70-210e-49e2-92d1-f9ad3823d7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving values sum acetyl/sum alpha normalized over length MT  in a file to open later again and do statistical analysis\n",
    "root=tkin.Tk()\n",
    "root.withdraw() \n",
    "my_working_path= filedialog.askdirectory(title=\"Choose folder in which other folders with the csv files from the linescan are found:\")# opens a window on your computer to select the folder\n",
    "os.chdir(my_working_path) \n",
    "work=os.getcwd()\n",
    "f = open('SUMAcetyl_DIV_SUMAlpha_for_timepoints_without_taxol', 'a')\n",
    "\n",
    "#f = open('AUC_lengthMT_for_timepoints', 'w')\n",
    "\n",
    "f.write(string48_x)\n",
    "f.write(string_sumdiv_y+\"\\n\")\n",
    "\n",
    "#good pracitice\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
